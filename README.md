# JuniorDesignApp

## Release Notes

## Installation Guide
### Install App
git clone https://github.com/Erickkbentz/JuniorDesignApp.git

cd JuniorDesignApp

git submodule init

git submodule update



### -- Setup Frontend and Prisma database client --
cd JuniorDesignFE
npm install

npm i -g prisma@latest

npm i @prisma/client@latest

prisma generate



### -- Setup Machine Learning --
cd ../JuniorDesignML

pip install Flask praw pandas numpy PyPDF2 nltk text2emotion datetime

python app.py

NOTE: If running into any bugs 'module xxx does not exist' run 'pip install xxx'

## Machine Learning Info

### -- Stage 1: Persuasion Detection --
For the persuasion detection file (located at JuniorDesignML/Models/PersuasionDetector/modelv3.ipyynb) we are doing a supervised text classification algorithm. We are primarily using the nltk, panas, and numpy libraries for data setup, preprocessing, and processing. To train the model, we used a test set generated by PRAW (using prawScript in the /OldOrTest folder). For persuasive examples we scraped the post bodies of r/UnpopularOpinion, and the comments of r/AmITheAsshole and r/ChangeMyView. For non persuasive examples we scraped the post comments from r/Gaming, r/WritingPrompts, and the post bodies of r/NoSleep. From there we created three feature sets (a count vector, a word vector, and an n-gram vector), and trained them on two different model types (Naive-Bayes and Linear Regression). At the bottom of the file we run each of the 6 models created against a manually created test set to gauge their accuracies. We found the Naive-Bayes Count Vector model performed best so that is the one being used in the dashboard currently. The file is set up so any new data set can be inputted and used to retrain the model in an attempt to increase its accuracy. 

### -- Stage 2: Persuasion Classification --


The most notable omission in our project is the lack of an unsupervised machine learning model to place persuasive text into groups. The ways we attempted to implement the unsupervised model were initially centered around a convolutional neural network. Such systems excel at finding abstractions within large bodies of data. This technique is most frequently used in tasks such as computer vision but from our research has been making moves into text classification. The way we attempted to implement this was to break down a paragraph, as an example, into a group of vectorized data know as parse tree, which represent the natual ways a body of text can be broken down through interpretation. This collection of vectors form a 2 dimensional array around which we convolve. This did not work through various attempts.

We tried multiple strategies to utilize a k-means clustering algorithm to classify persuasion. Nothing we did seemed to organize the resulting clusters in a productive way. We tried introducing bias by searching for keywords within the text that might indicate logos, ethos, or pathos, and concattonated "logos", "ethos", "pathos" to the end of the string accordingly. (i.e. if it is rainy, then you need an umbrella logos). We thought it would help the allgorithm better find a pattern within texts containing keywords. This did not work.

Ultimatly what we use is a system that scans the bodies of text for the most basic attributes of the type of classification. For logos we count the usage of the words, "if/then" and count the number of digits used. Similarly for Ethos we count the use of Proper nouns. For pathos we ran each body of text through a sentiment anaysis api know as text2emotion. This sentiment analysis provided a score for 5 attributes whose sum is equal to 1 unless none of the perscribed emotions were found. These emotions were: Anger, Fear, Happy, Surprise and Sad. To use this data as a categorization tool we summed the scores for Anger and Fear from a belief these would be the emotions most likely used in a persuasive context. With some baseline heuristic for Logos, Ethos and Pathos we normalized our scores to provide a score for each category as a percentage.
